{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microscope Project Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "\n",
    "from pandas import DataFrame         # to build our table of data from the video.\n",
    "import pims                          # to import the video.\n",
    "import scipy.ndimage as nd           # for Gaussian filter.\n",
    "from skimage import filters\n",
    "\n",
    "import trackpy as tp                 # for object tracking functions.\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'  # to set our default colourmap as grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the video into the variable 'frames'.\n",
    "# Change 'path' to directory of images\n",
    "\n",
    "\n",
    "\n",
    "frames_full_video = pims.Video( '/Volumes/Stan_16GB/Week_3/Primo Star (2nd)/Immotile_primo_w3.m4v' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the properties of frames_full_video to get total number and shape.\n",
    "\n",
    "print( frames_full_video ) # Also see how many fps as this will affect the crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = frames_full_video[60:420] # 15 seconds so that the computer can process better (24fps)\n",
    "frames_full_video = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the properties of frames to get total number and shape.\n",
    "\n",
    "print( frames )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the red, green and blue channels of the first frame\n",
    "\n",
    "fig, ax = plt.subplots( nrows = 1, ncols = 3, figsize = (14, 5) )\n",
    "\n",
    "ax[0].imshow( frames[0][:,:,0] )\n",
    "ax[1].imshow( frames[0][:,:,1] )\n",
    "ax[2].imshow( frames[0][200:900,300:1500,2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "First, we need to crop the image and choose a colour channel to work with. This makes downstream processing much faster and removes shadowed areas of the image. Like the week 5 example, you may need to change the area you are looking at as the 'slice' values are currently set to the example video.\n",
    "## Once you have settled on a crop you need to keep these settings for all repeats and strains.\n",
    "Remember the format of the slice is Y1 Y2 X1 X2, where '1' is the top left corner and '2' is the bottom right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As in the previous notebook, let's define a crop and choose the red channel to work with\n",
    "\n",
    "crop = (slice(200, 900), slice(300, 1500), 2)\n",
    "# frames_crop = [frame[200:900,300:1500,2] for frame in frames]\n",
    "frames_crop = np.array( [frame[crop] for frame in frames], dtype=float )\n",
    "frames = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a frame of the cropped image to check progress.\n",
    "# You need to make sure you have an even level of brightness across the background.\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(frames_crop[0] )\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moving = frames_crop - np.median(frames_crop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_crop100 = frames_crop[100] # use whichever frame is annotated later with the circles to look for false positives\n",
    "frames_crop = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.imshow(moving[100] )\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to reduce noise within the image. We can do this by applying a Gaussian filter that will blur the image and subdue noisy pixels. The numbers in brackets are the sigma values for the filter specified for two dimensions only. This ensures the filter is only applied to the X and Y dimensions and not to the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a filtered version of the array\n",
    "\n",
    "frames_filter = np.array( [ nd.filters.gaussian_filter(frame, [2, 2] ) for frame in moving] )\n",
    "moving = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.imshow( frames_filter[100] )\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "Your data will need careful thresholding to remove background. In the code below, the variable 'thresh' is '130'. This means that any feature brighter than 130 will be discarded. You may need to alter this value for your own images, depending on the brightness of the background. We also invert the immage so that the black dots become white dots, which makes downstream processing more intuitive (i.e. higher pixel values mean a higher chance those pixels are part of an object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The command below makes a binary image from the inverted original image. The threshold is set manually here.\n",
    "# By using the threshold we remove any lighter noise that can confuse the tracking.\n",
    "# For later analysis, we need to convert the type of this array to 'uint8' \n",
    "\n",
    "#thresh = -5\n",
    "\n",
    "#frames_inv = np.array( [ (frame > thresh)*255 for frame in frames_filter] ).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check one of these binary frames\n",
    "#print(frames_filter[100].max())\n",
    "#plt.figure()\n",
    "\n",
    "#plt.imshow( frames_inv[100] )\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow( 255-frames_inv[100] )\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frames_inv2 = 255 - frames_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = filters.threshold_otsu(frames_filter) # Otsu method of thresholding. # if it fails use -20\n",
    "\n",
    "invertval = frames_filter < val\n",
    "frames_filter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(invertval[100])#, cmap='gray')#, interpolation='nearest')\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import imageio\n",
    "#kargs = {'macro_block_size': None}\n",
    "#imageio.mimsave(r'c:\\Users\\swn202\\Documents\\test_int.mp4', \n",
    "#                invertval[:100].astype(np.uint8),'MP4',**kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#?imageio.mimsave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrackPy\n",
    "This section of the script utilises TrackPy. We will use it to locate the cells and to track the movement of each cell over time. From this we will be able to determine track length of the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function below searches the image for objects of 21 pixels in diameter.\n",
    "# It returns a pandas dataframe of information about all objects it finds.\n",
    "# It is looking for bright spots in the image, which is one reason for inverting the images above.\n",
    "\n",
    "cell = tp.locate( invertval[100], 21, invert = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#?tp.locate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The results can be plotted on top of the original image.\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "tp.annotate(cell, frames_crop100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function below executes the same search on all frames.\n",
    "# Note: if there are many features/frames, this can take a while to execute.\n",
    "# The minmass kwarg is a threshold for the 'bright' points. In our case, values are either 255 or 0\n",
    "# so any number in between is fine.\n",
    "# Above two statements are not necessarily true as the data type is now a float - for Apex_test1, Otsus, it is 0 or 1\n",
    "# You might want to limit the range to the first 100 frames to start with to see what is happening.\n",
    "\n",
    "cells = tp.batch( invertval, 21, minmass = 0.8, invert = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The features (cell positions) can now be linked.\n",
    "# The number '10' is the maximum 'step' in pixels allowed between frames so\n",
    "#     for fast moving chlamy this should be increased, keep consistent. # 30 to 50 is good depending on speed in video\n",
    "#     It is the search range\n",
    "# Memory is the number of frames a chlamy can disappear for\n",
    "\n",
    "tracks = tp.link_df( cells, 50, memory = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tp.plot_traj(tracks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#?tp.link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Just for visualisation\n",
    "# To measure 'genuine' tracks (as opposed to noise) we should remove short tracks\n",
    "# We shall use a cut-off of 50.\n",
    "# This is the number of frames that it must be tracked. For 100 frames this is too high\n",
    "\n",
    "tracks_long = tp.filter_stubs( tracks, 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The moment of truth! The tracks can now be plotted.\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "tp.plot_traj( tracks_long );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track length\n",
    "Plot histogram \n",
    "Try for before and after the background subtraction to see if there is a difference - should remove really long tracks\n",
    "Find average\n",
    "Convert to microns to standardise between each microscope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conversion of pixels to micrometres using conversion data already calculated\n",
    "# 0.0936 Primo\n",
    "# 0.0945 Apex\n",
    "# 0.0880 My 1st\n",
    "\n",
    "f['xum'] = f['x'] * 0.0880\n",
    "f['yum'] = f['y'] * 0.0880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tracks in micrometres instead of frames\n",
    "linked = tp.link_df( f, 50, memory = 3 )\n",
    "tracks = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normed = True makes it realtive frequency\n",
    "#linked = tracks #tp.link_df(f, 6)\n",
    "\n",
    "hist, bins = np.histogram(np.bincount(linked.particle.astype(int)), bins=np.arange(0,25), normed=True)\n",
    "plt.step(bins[1:], hist)\n",
    "plt.xlabel('Track Length')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist1, bins1 = np.histogram(np.bincount(linked.particle.astype(int)), bins=np.arange(0,25))\n",
    "hist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist2 = np.delete(hist1, [0], None)\n",
    "hist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt('freq.csv', hist2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_freq = 0\n",
    "for i in hist2:\n",
    "    total_freq += i\n",
    "total_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hist1, bins1 = np.histogram(np.bincount(linked.particle.astype(int)), bins=np.arange(0,25))\n",
    "plt.step(bins1[1:], hist1)\n",
    "plt.xlabel('Track Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins2 = np.linspace(0.5,23.5,num = 47)\n",
    "bins2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mid_bins = bins2[::2]\n",
    "mid_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_y0 = hist1*mid_bins\n",
    "x_y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_y = np.delete(x_y0, [0], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt('freq_times_bin.csv', x_y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sort(x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_yt = 0\n",
    "for n in x_y:\n",
    "    x_yt += n\n",
    "x_yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_len = (x_yt)/total_freq\n",
    "mean_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cum_freq = hist1.cumsum()\n",
    "cum_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prop_greater_that_prev = 1 - cum_freq / cum_freq[-1]\n",
    "prop_greater_that_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins3 = np.delete(bins1, [24], None)\n",
    "bins3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(prop_greater_that_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(bins3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median in value found between the proportions ??? and ???\n",
    "#### This falls between bin ? and ? \n",
    "#### NB counting from 0,1,2,3,4,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bins3,prop_greater_that_prev)\n",
    "plt.stem(bins3,prop_greater_that_prev)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('/Users/Stan/Desktop/Uni/Frontiers/Project (microscopes)/Medians/median_immotile_primo_w3.csv', prop_greater_that_prev, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_length = ([mean_len])\n",
    "mean_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('/Users/Stan/Desktop/Uni/Frontiers/Project (microscopes)/Means/mean_immotile_primo_w3.csv', mean_length, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
